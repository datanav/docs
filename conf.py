#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) Bouvet ASA - All Rights Reserved.
# Unauthorized copying of this file, via any medium is strictly prohibited.

import os
import sys

import cornice
import guzzle_sphinx_theme

# import sphinx_rtd_theme


# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute.
sys.path.insert(0, os.path.abspath(cornice.__file__))

# Add the sesamclient to the path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../../client")))

import pprint
print ("sys.path:%s" % pprint.pformat(sys.path))


# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = ['sphinxarg.ext',
              'sphinxcontrib.openapi'
              ]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix(es) of source filenames.
# You can specify multiple suffix as a list of string:
# source_suffix = ['.rst', '.md']
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Sesam'
copyright = '2021 Sesam.io AS'
author = 'The Sesam Team'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = 'x.y'
# The full version, including alpha/beta/rc tags.
release = 'who cares'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#
# This is also used if you do content translation via gettext catalogs.
# Usually you set "language" from the command line for these cases.
language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build', os.path.basename(os.environ['VIRTUAL_ENV']), 'git.rst', 'project-setup.rst', 'training/courses/*.rst']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False

# If true, `todo` and `todoList` produce output, else they produce nothing.
todo_include_todos = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
# html_theme = 'alabaster'
# html_theme = "sphinx_rtd_theme"

# Adds an HTML table visitor to apply Bootstrap table classes
html_theme_path = guzzle_sphinx_theme.html_theme_path()
html_theme = 'guzzle_sphinx_theme'

# Register the theme as an extension to generate a sitemap.xml
extensions.append("guzzle_sphinx_theme")

# Guzzle theme options (see theme.conf for more information)
html_theme_options = {
   # Set the name of the project to appear in the sidebar
   "project_nav_name": "Sesam",
}

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []
#html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
html_title = "Sesam documentation"

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = []

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Language to be used for generating the HTML full-text search index.
# Sphinx supports the following languages:
#   'da', 'de', 'en', 'es', 'fi', 'fr', 'h', 'it', 'ja'
#   'nl', 'no', 'pt', 'ro', 'r', 'sv', 'tr'
#html_search_language = 'en'

# A dictionary with options for the search language support, empty by default.
# Now only 'ja' uses this config value
#html_search_options = {'type': 'default'}

# The name of a javascript file (relative to the configuration directory) that
# implements a search results scorer. If empty, the default will be used.
#html_search_scorer = 'scorer.js'

# Output file base name for HTML help builder.
htmlhelp_basename = 'Sesamdoc'

# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',

# Latex figure (float) alignment
#'figure_align': 'htbp',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  (master_doc, 'Sesam.tex', 'Sesam Documentation',
   'Graham Moore', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    (master_doc, 'sesam', 'Sesam Documentation',
     [author], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  (master_doc, 'Sesam', 'Sesam Documentation',
   author, 'Sesam', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False


####### TRAINING COURSE AUTOMATION STARTS HERE #######


import pathlib
import shutil
import os
from json import dumps as dump_json
from pptx import Presentation
from pptx.shapes.autoshape import Shape
import copy

def summarizer(text: str):
    output = {}
    curMain = None
    for line in text.split('\n'):
        if line.startswith('  - '):
            curMain = line.replace('  - ', '')
            output[curMain] = []
        elif line.startswith('    - '):
            output[curMain].append('     ' + line)
    return output


def findTextBox(presentation: Presentation):
    for slide in presentation.slides:
        for shape in slide.shapes:
            if not shape.has_text_frame:
                continue
            if type(shape) == Shape:
                return shape.text_frame


def replace_paragraph_text_retaining_initial_formatting(paragraph, new_text):
    p = paragraph._p  # the lxml element containing the `<a:p>` paragraph element
    # remove all but the first run
    ###DEBUG###
    # print(f'For paragraph {paragraph} with runs "{paragraph.runs}" adding text {new_text}')
    ###DEBUG###
    for idx, run in enumerate(paragraph.runs):
        if idx == 0:
            continue
        p.remove(run._r)
    paragraph.runs[0].text = new_text

def replaceTitle(presentation: Presentation, new_title):
    title_box = presentation.slides[0].shapes.title.text_frame.paragraphs[0]
    replace_paragraph_text_retaining_initial_formatting(title_box, new_title)




def replaceBulletPoints(textframe, inputdict: dict):
    #Prøv å bruk tab indent i str for å indentere bullet points
    def copy_run(run_from, run_to):
        r_to = run_to._r
        r_to.addnext(copy.deepcopy(run_from._r))
        r_to.getparent().remove(r_to)

    def copy_paragraph(paragraph_from, paragraph_to):
        p_to = paragraph_to._p
        p_to.addnext(copy.deepcopy(paragraph_from._p))
        p_to.getparent().remove(p_to)

    first_paragraph = textframe.paragraphs[0]
    first_paragraph_run = textframe.paragraphs[0].runs[0]
    i = 0
    for key in inputdict:
        if len(textframe.paragraphs) < i + 1:
            p = textframe.add_paragraph()
            copy_paragraph(paragraph_from=first_paragraph, paragraph_to=p)
        replace_paragraph_text_retaining_initial_formatting(textframe.paragraphs[i], key)
        i += 1
        for subpoints in inputdict[key]:
            p = textframe.add_paragraph()
            r = p.add_run()
            copy_run(run_from=first_paragraph_run, run_to=r)
            replace_paragraph_text_retaining_initial_formatting(textframe.paragraphs[i], subpoints)
            i += 1


def createPres(topic: list, template_slide_path, outputFolder=''):
  if 'summary' in topic:
      prs = Presentation(template_slide_path)
      replaceTitle(prs, topic['title'])
      text_box = findTextBox(prs)
      replaceBulletPoints(text_box, summarizer(topic['summary']))
      print(f"Created '{outputFolder}{topic['reference'][4:-1]}.pptx'")
      prs.save(f"{outputFolder}{topic['reference'][4:-1]}.pptx")
  else:
      print(f"Topic {topic['title']} has no sumamry. Skipping PPT creation.")


def find_root_headers(root_level_header, file=None, inputString=None, sourceFile=None):
    """
    I'm a function which finds all the root level headers in a document.
    """
    if file:
        lines = open(file).readlines()
        sourceFile = file
    elif inputString:
        lines = inputString.split('\n')
    else:
        print('find_root_headers function in conf.py got None as input!')
    cur_ref = None
    tmp_cur_ref = None
    prev_line = None
    returnlist = []
    for l in lines:
        l = l.replace('\n', '')
        if l.startswith('.. _') and l.endswith(':'):
            tmp_cur_ref = l
        linelength = len(l)
        reflength = 0
        for c in l:
            if c == root_level_header:
                reflength += 1
        if linelength == reflength and linelength != 0:
            cur_ref = tmp_cur_ref
            returnlist.append({
                "reference": cur_ref,
                "title": prev_line,
                "source_file": sourceFile
            })
        prev_line = l


    return returnlist

def createFiles(splitonthis: list, inputFile=None, inputString=None):
    """
    I'm a function which a splits a string on a list of strings.
    I make sure that there is no overlap in the output strings.
    """
    if inputFile:
        input = open(inputFile).read()
    elif inputString:
        input = inputString
    else:
        print('createFiles function in conf.py only got None as input!')
    splitonthis.reverse()
    #print('SPLITTING ON' + str(splitonthis))
    for x, e in enumerate(splitonthis):
        splitted_main_file = input.split(e['reference'])
        if splitted_main_file:
            input = splitted_main_file[0]
        ref_name = f".. _{e['reference'][4:]}"
        e['text'] = ref_name + splitted_main_file[-1]
    splitonthis.reverse()
    return splitonthis


def split_training_into_topics(root_level_header, files, output_folder, rename_ref_prefix):
    """
    I use the functions within me to split RST files into a file for each
    root level header in the file.
    """
    total_topics = []
    for f in files:
        filenameSplitted = f.split('/')[-2:]
        topics = find_root_headers(root_level_header=root_level_header, file=f)
        from json import dumps
        file = open(f).read()
        total_topics += createFiles(inputFile=f, splitonthis=topics)

    return total_topics

def get_courses(folder):
    output = []
    for course_name in [e[0:-4] for e in os.listdir(folder) if e.endswith('.rst')]:
        curpath = os.path.join(folder, f'{course_name}.rst')
        output.append({"course_name": course_name, "course_file_path": curpath})
    return output

def replace_course_file_content(course, rename_ref_prefix, topics):
    with open(course["course_file_path"], 'r+') as f:
        content = f.readlines()
        newfile = ""
        for line in content:
            curRef = None
            curLine = line
            if line.startswith('   ###') and line.endswith('###\n'):
                curRef = line[6:-4]
                found = False
                for t in topics:
                    if t["reference"] == curRef:
                        found = True
                        curLine = t['text']
                        topic_media_folder = f'../../../{"/".join(t["source_file"].split("/")[0:-1])}/media/'
                        curLine = curLine.replace('.. figure:: ./media/', f'.. figure:: {topic_media_folder}')
                        createPres(t,
                         '/Users/gabriell.vig/Work/Sesam/docs/training/powerpoints/splitme.pptx',
                         f'/Users/gabriell.vig/Work/Sesam/docs/training/courses/{rename_ref_prefix}')
                        break
                if found == False:
                    raise Exception(f'Could not find reference {curRef} in training docs!')
            curLine = curLine.replace('.. _', f'.. _{rename_ref_prefix}')
            newfile += curLine
        f.close()
        return course, newfile


def find_summaries(topics):
    for t in topics:
        summaries = []
        curSummary = ''
        curSummaryTextFound = False
        atSummary = False
        test = False
        for line in t['text'].split('\n'):
            if line == '.. sidebar:: Summary':
                atSummary = True
            if atSummary and (line.startswith('  ') or line == ''):
                if line != '':
                    curSummary += line + '\n'
                curSummaryTextFound = True
            elif atSummary and curSummaryTextFound:
                summaries.append(curSummary)
                curSummary = ''
                atSummary = False
                curSummaryTextFound = False


        if len(summaries) > 0:
            t['summary']  = summaries[-1]

def create_course_files(new_course_files, directory):
    if os.path.exists(directory):
        shutil.rmtree(directory)
    os.makedirs(directory)
    for course_info, file_content in new_course_files:
        newfile_path = os.path.join(directory, f'{course_info["course_name"]}.rst')
        with open(newfile_path, 'w') as newfile:
            newfile.write(file_content)
            newfile.close()

def create_courses(files, output_folder, courses_path, root_level_header, rename_ref_prefix):

    output_folder_full_path = os.path.join(pathlib.Path().absolute(), output_folder)
    courses_path_full = os.path.join(pathlib.Path().absolute(), courses_path)
    topics = split_training_into_topics(root_level_header, files, output_folder, rename_ref_prefix)

    subTopics = []
    for t in topics:
        curHeaders = find_root_headers(root_level_header='^', inputString=t['text'], sourceFile=t['source_file'])
        curTopics = createFiles(splitonthis=curHeaders, inputString=t['text'])
        subTopics = subTopics + curTopics
    topics = topics + subTopics
    find_summaries(topics)
    ###DEBUG###
    for t in topics:
        if 'summary' in t:
            print(dump_json(t, indent=2))
    ###DEBUG###
    courses = get_courses(courses_path_full)
    new_course_files = []
    for course in courses:
        new_course_files.append(replace_course_file_content(course, rename_ref_prefix, topics))
    create_course_files(new_course_files, output_folder_full_path)



training_files = ["training/010_architecture_and_concepts/020_Beginner.rst","training/010_architecture_and_concepts/030_Novice.rst","training/010_architecture_and_concepts/040_Intermediate.rst","training/010_architecture_and_concepts/050_Advanced.rst","training/010_architecture_and_concepts/060_Epilogue.rst","training/010_architecture_and_concepts/architecture_and_concepts.rst","training/020_systems/020_Beginner.rst","training/020_systems/030_Novice.rst","training/020_systems/040_Intermediate.rst","training/020_systems/060_Epilogue.rst","training/020_systems/systems.rst","training/030_dtl/020_Beginner.rst","training/030_dtl/030_Novice.rst","training/030_dtl/040_Intermediate.rst","training/030_dtl/050_Advanced.rst","training/030_dtl/060_Epilogue.rst","training/030_dtl/dtl.rst","training/040_projects_and_infrastructure/020_Beginner.rst","training/040_projects_and_infrastructure/030_Novice.rst","training/040_projects_and_infrastructure/040_Intermediate.rst","training/040_projects_and_infrastructure/060_Epilogue.rst","training/040_projects_and_infrastructure/projects_and_infrastructure.rst","training/050_microservices/020_Beginner.rst","training/050_microservices/030_Novice.rst","training/050_microservices/040_Intermediate.rst","training/050_microservices/050_Advanced.rst","training/050_microservices/060_Epilogue.rst","training/050_microservices/microservices.rst","training/060_sesam_in_the_wild/020_Beginner.rst","training/060_sesam_in_the_wild/030_Novice.rst","training/060_sesam_in_the_wild/040_Intermediate.rst","training/060_sesam_in_the_wild/050_Advanced.rst","training/060_sesam_in_the_wild/060_Epilogue.rst","training/060_sesam_in_the_wild/sesam_in_the_wild.rst"]
#training_files = ["training/010_architecture_and_concepts/020_Beginner.rst"]
training_output_folder = 'training/courses/tmp'
training_COURSES_PATH = 'training/courses'
training_root_level_header = '~'
training_rename_ref_prefix = 'tc_'
create_courses(training_files, training_output_folder, training_COURSES_PATH, training_root_level_header, training_rename_ref_prefix)

####### TRAINING COURSE AUTMATION ENDS HERE #######
